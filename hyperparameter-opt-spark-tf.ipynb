{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch(spark_session, map_fun, args_dict):\n",
    "    \"\"\" Run the wrapper function with each hyperparameter combination as specified by the dictionary\n",
    "\n",
    "    Args:\n",
    "      :spark_session: SparkSession object\n",
    "      :map_fun: The TensorFlow function to run\n",
    "      :args_dict: A dictionary containing hyperparameter values to insert as arguments for each TensorFlow job\n",
    "    \"\"\"\n",
    "\n",
    "    sc = spark_session.sparkContext\n",
    "\n",
    "    # Length of the list of the first list of arguments represents the number of Spark tasks\n",
    "    num_tasks = len(args_dict.values()[0])\n",
    "\n",
    "    # Create a number of partitions (tasks)\n",
    "    nodeRDD = sc.parallelize(range(num_tasks), num_tasks)\n",
    "\n",
    "    # Execute each of the hyperparameter arguments as a task\n",
    "    nodeRDD.foreachPartition(_do_search(map_fun, args_dict))\n",
    "\n",
    "\n",
    "def _do_search(map_fun, args_dict):\n",
    "    \n",
    "    def _wrapper_fun(iter):\n",
    "\n",
    "        for i in iter:\n",
    "            executor_num = i\n",
    "\n",
    "        argcount = map_fun.func_code.co_argcount\n",
    "        names = map_fun.func_code.co_varnames\n",
    "\n",
    "        args = []\n",
    "        argIndex = 0\n",
    "        while argcount > 0:\n",
    "            # Get arguments for hyperparameter combination\n",
    "            param_name = names[argIndex]\n",
    "            param_val = args_dict[param_name][executor_num]\n",
    "            args.append(param_val)\n",
    "            argcount -= 1\n",
    "            argIndex += 1\n",
    "        map_fun(*args)\n",
    "    return _wrapper_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
